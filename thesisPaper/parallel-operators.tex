\chapter{Proposed Operators for a Parallel Implementation of J} 
\label{paraop}

\section{Rationale}
Ideally, a program would automatically reduce runtime by using a parallel library, 
without requiring the programmer to write a single line of parallelizing code. 
However, this is often not the case. 
Frequently, programmers must use domain knowledge of the problem or platform to achieve good run-time results. 

In order to grant this flexibility in future parallel implementations of J, 
we propose introducing two new operators, called the \textit{parallel rank operator} 
and the \textit{parallel insert operator}.
The \textit{parallel rank operator}, described in Section \ref{prank}, 
would allow the programmer to specify the ranks on which to parallelize code.
The \textit{parallel insert operator}, described in Section \ref{pins}, 
would allow the programmer to parallelize reduction operations with associative functions.
Additionally, we propose a new system library
that would allow the programmer to give annotations or force changes in the underlying parallel environment,
described in Section \ref{pfor}

The spellings \texttt{"::}  and \texttt{/::} for the two parallel operators were chosen for mnemonic and compliance reasons.
Mnemonically, each uses the same base character as their sequential analogs, (\texttt{"} and \texttt{/}), 
as well as two ``parallel'' colons, making it easier to remember their functions.
They also require no changes be made to the existing J lexer\cite{ioj}, 
as demonstrated below:

\begin{singlespacing}
\begin{small}
\begin{verbatim}
   NB. The J Lexer as a primitive
   NB. Takes a character string and 
   NB. puts each lexeme in a `box'
   jlexer =: ;:
   jlexer '+/::("1) mat2_3 +("::1)("2) arr2_2_3'
+-+---+-+-+-+-+------+-+-+---+-+-+-+-+-+-+--------+
|+|/::|(|"|1|)|mat2_3|+|(|"::|1|)|(|"|2|)|arr2_2_3|
+-+---+-+-+-+-+------+-+-+---+-+-+-+-+-+-+--------+
\end{verbatim}
\end{small}
\end{singlespacing}

For the purposes of this discussion, the important result the above example demonstrates 
is that the string of characters \texttt{"::} is read as a whole lexeme, and is placed entirely in a box, 
rather than being interpreted as several lexemes, 
which would result in the characters being split into several boxes.
For more detail on the behavior of the J language, consult Appendix \ref{jlex}. % TODO footnote!

For the parallel environment library, 
it seemed best to augment the existing ``\gls{foreign}'' operator (spelled \texttt{!:}).  
The foreign operator was designed to 
allow the programmer to change environmental parameters 
such as print precision, file I/O, etc\cite{jvocab}, 
and so fits conceptually with the idea of changing the state of a parallel environment. 
We chose $111$ as the numeric encoding for the parallel environment library, again for mnemonic reasons: 
$111$ looks like three parallel lines ($11$ was already taken).

\section{Parallel Rank Operator: \texttt{"::}}
\label{prank}

\subsection{Usage}
The proposed parallel rank operator is a conjunction 
whose first argument is a function 
and whose second argument is the ranks to both apply the function and to parallelize it. 
It would be functionally equivalent to the rank operator, i.e. 
\[\texttt{f (":: r) y} \Leftrightarrow \texttt{f (" r) y}\] and
\[\texttt{x f (":: r) y} \Leftrightarrow \texttt{x f (" r) y}\]

for all $f, r, s$, and $y$

Its purpose would be to override other parallel system defaults for automatic parallelization
to guarantee that the resulting function would create parallelizable tasks from 
the operations on sub-arrays of the given rank that would then be distributed to the available threads.
To illustrate, consider the examples in Fig~\ref{fig::pr_tasks}.
Incrementing numeric values always applies to scalars, so the function \texttt{increment} always gives the same result, 
regardless of the rank of the sub-collections to which it is applied. 
Using the parallel rank operator, the behavior increment of 
always having the same result regardless of the rank applied would remain; 
however, as the last example visually illustrates, 
specifying \texttt{increment (":: 1)} would result in the environment parallelizing 
the operation of incrementing each of the vector elements of \texttt{mat2\_3}.
In this example, a programmer could create parallelizable tasks from incrementing 
the six scalars, the two vectors, and the one matrix.

\pagebreak

\glsadd{increment}
\glsadd{showTasks}
\begin{figure}[h]
\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   NB. increment: increments the values of a numeric array
   increment =: >:
   increment mat2_3
1 2 3
4 5 6
   NB. Link places both its arguments in `boxes'
   NB. This demonstrates that incrementing a collection
   NB. is the same regardless of the rank applied
   (increment"0 link increment"1 (link =: ;) increment"2) mat2_3
+-----+-----+-----+
|1 2 3|1 2 3|1 2 3|
|4 5 6|4 5 6|4 5 6|
+-----+-----+-----+
   NB. showTasks visualizes how the subcollections of mat2_3
   NB. would be broken up into tasks that would then be 
   NB. concurrently operated on ny threads
   showTasks =: agreement (< @)
      (increment (" 1) showTasks) mat2_3
+-----+-----+
|0 1 2|3 4 5|
+-----+-----+
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing tasks created by the parallel rank operator}
\label{fig::pr_tasks}
\end{figure}

A more complex example involving functions of two arguments, 
as well as repeated applications of the rank operator, is given in Fig~\ref{fig::pr_tasks2}.
Using the parallel rank operator, the line of code
\texttt{mat2\_3 +("::2) arr2\_2\_3} would create parallelizable tasks for adding the elements of each of the two matrices, whereas 
\texttt{mat2\_3 +("::1)("2) arr2\_2\_3} would create parallelizable tasks for adding the elements of each of the four vectors.

\begin{figure}[p]
\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   show arr2_2_3 =: integers 2 2 3
0  1  2
3  4  5

6  7  8
9 10 11
   mat2_3 +"2 arr2_2_3
0  2  4
6  8 10

6  8 10
12 14 16
   mat2_3 +("1)("2) arr2_2_3
0  2  4
6  8 10

 6  8 10
12 14 16
   mat2_3 (+("2) showTasks) arr2_2_3
+-------------+---------------+
|+-----+-----+|+-----+-------+|
||0 1 2|0 1 2|||0 1 2|6  7  8||
||3 4 5|3 4 5|||3 4 5|9 10 11||
|+-----+-----+|+-----+-------+|
+-------------+---------------+
   mat2_3 (+("1) showTasks) arr2_2_3
+-------------+---------------+
|+-----+-----+|+-----+-----+  |
||0 1 2|0 1 2|||3 4 5|3 4 5|  |
|+-----+-----+|+-----+-----+  |
+-------------+---------------+
|+-----+-----+|+-----+-------+|
||0 1 2|6 7 8|||3 4 5|9 10 11||
|+-----+-----+|+-----+-------+|
+-------------+---------------+
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing tasks created by the parallel rank operator for two collections}
\label{fig::pr_tasks2}
\end{figure}

Some open questions remain, most notably 
the behavior of the parallel environment when multiple applications of the parallel rank operator are used. 
For example, should multiple applications of the parallel rank operator result in multiple levels of parallelizable task creation, 
leading to increased overhead from thread creation and scheduling, 
or should the outermost application determine the only level at which parallizable tasks are created, 
leading to unparallelizing previously parallelized programs when they are used in larger functions? 
Either possibility having significant impact on program run time.
One solution may be to allow the programmer to chose which behavior best suites their needs 
using the parallel environment libary, described in Section \ref{pfor}.

\section{Parallel Insert Operator: \texttt{/::}}
\label{pins}
\subsection{Rationale}
Frequently, programmers need to perform some sort of reduction operation on an entire collection, 
for example finding the sum, product, maximum, minimum, etc. of a collection of numbers.
It's well known that when the reducing operation $f$ is associative, 
i.e. when $f(x,y) = f(y,x)$ for all $f, x, y$ (and for a sufficiently tolerant comparison, when dealing with floating point values),
then the reduction can be carried out in a parallel fashion with little effort on the programmer's part.
Therefor, a future parallel implementations of J should allow the programmer 
to explicitly state that a specific associative function should be used to reduce an array in parallel, 
since in the general case the default insert operator does not assume its argument function is associative, 
nor is it immediately obvious how to determine if a user-defined function is associative.

\subsection{Usage}
As a unary, higher ordered function (\textit{adverb}), 
the parallel insert operator would be equivalent to the sequential insert operator 
for all associative operations. 
Thus, the J session depicted in Fig~\ref{fig::pinsert} would have the same results for every line of code executed, 
regardless of whether \texttt{insert} was assigned to be \texttt{/::} or \texttt{/}

\glsadd{insert}
\begin{figure}[h]
\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   insert =: /
   show vec10 =: integers 10
0 1 2 3 4 5 6 7 8 9
   + insert vec10
45
   NB. greaterOf takes two numbers
   NB. and returns the greater of them
   100 (greaterOf =: >.) 10
100
   greaterOf insert vec10
9
   + insert mat2_3
3 5 7
   NB. Flatten takes any array
   NB. and converts it to a vector
   + insert (flatten =: ,) mat2_3
15
   NB. sum each of the vectors
   NB. in mat2_3
   + insert ("1) mat2_3
3 12
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Using the parallel insert operator}
\label{fig::pinsert}
\end{figure}

An open question remains about how the parallel insert operator should behave on non-associative functions. 
Without associativity, the results of reducing an array with a function depend on the order by which the function is applied, 
destroying the possibility of concurrent operations.
One possibility way to deal with non-associativity is to define domain of parallel insert to be only the associative primitives. 
This would prevent logical errors such as radically different results for the same calculations on the same data, 
depending on the thread scheduling scheme. 
However, this approach would likely require adding an additional table of information 
that would store whether or not the given primitive was associative.
This approach would also exclude the possibility of 
user-defined functions that are associative from benefiting from parallelization. 

Another possibility would be ignore the question of whether or not a function \texttt{f} is associative, 
and try to parallelize \texttt{f} as if it were associative.
Using this approach could lead to errors that might be difficult for a novice parallel programmer to debug and may even go unnoticed, 
since those errors would be at the logic-level and not during run-time.
Finally, a middle solution could be taken in which the programmer chooses to switch between these approaches using the parallel environment library, 
discussed below.

\section{Parallel Environment Library: \texttt{111 !:}} 
\label{pfor}

\subsection{Conventions of the Foreign Operator}
The foreign operator is a two-argument higher order function, or in J a \textit{conjunction}, 
whose arguments are always numeric.
Conceptually, these arguments serve as an index into system libraries and functions.
The left argument indexes the desired library.
E.g., $2$ indexes the library for functions which affect the host machine, 
$9$ indexes the library for viewing and setting global J parameters (such as print precision), and etc.
The second argument indexes a specific function.
For example, \texttt{9!:6}  is the function which displays the print characters for J's box type.

\subsection{Usage}
There are many options to consider for implementing a full suite of functions for a parallel environment library.
A more full review of the functionality of other shared-memory parallel libraries, such as OpenMP\cite{openmp}, 
to make sure such a library provides all the functionality parallel programmers expect.
However, two types of functionality would almost certainly be required.
They are:

\begin{enumerate}
    \item Getting and setting the total number of threads available in the parallel environment,
        with an extension for J's value for infinity to mean no user-specified limit on the number of threads, and
    \item Getting and setting the thread scheduling schemes (such as static, round-robin, etc.).
        These would be encoded as numeric values, in keeping with the conventions of the foreign libraries.
\end{enumerate}

\noindent Additionally, as discussed in Sections \ref{pfor} and \ref{pins}, it may be desirable to change 
the default behavior of the parallel rank operator and/or parallel insert operator, 
in order to parallelize on user-defined associative operators.

\begin{figure}
\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   (111 !: 0) '' NB. Get number of threads.
1
   (111 !: 1) 4 NB. Set number of available threads to 4.

   (111 !: 2) '' NB. Get numeric encoding of thread scheduling scheme.
0
   (111 !: 3) 1 NB. Set thread scheduling to, for example, round robin.

   (111 !: 4) '' NB. Get parallel rank nested thread creation flag
0
   (111 !: 5) 1 NB. Enable nested thread creation

   (111 !: 6) '' NB. Get parallel insert restriction flag
0
   (111 !: 7) 1 NB. Enable restrictions on insert

   +/::("1) mat2_3 +("::1)("2) arr2_2_3
 6 24
24 42
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}
\caption{A hypothetical J session using the parallel environment library}
\label{fig::pfor}
\end{figure}

The example given in Fig~\ref{fig::pfor} is not based on any existing J REPL, 
but an illustration of how programmers might use this proposed library.
The last line would parallelize addition on the row elements of \texttt{mat2\_3} and \texttt{arr2\_2\_3},
then parallelize the sum operation on each of the vectors of the resulting array, 
using 4 threads with a round-robin scheduling scheme.
