\chapter{Background}
\label{back}

\section{Function Rank}
This section provides background information to help the reader understand 
what function rank is and how it can help programmers exploit data parallelism.

\subsection{History and Definition}
\textit{Function rank} was first developed and described by Kenneth Iverson in a series of research reports written at IBM\cite{rapl}\cite{opandfunc}. 
In one report, Iverson described it as 
``the most important notion needed to provide a simple and systematic basis for the uniform treatment of all `mixed' or non-scalar functions''\cite{rapl}. % TODO footnote of next comment
Since that time, the idea of function rank has matured and found its way into many dialects of APL, including J.

J's model of function rank is slightly different from the model originally presented by Iverson\cite{rankanduni}\cite{jvocab}. 
In J, the rank of a function \texttt{f} is a vector \texttt{v} of three values that represents the data rank of \texttt{f}'s expected arguments.
Since in J functions take either one or two arguments, 
the first value of \texttt{v} represents the rank of \texttt{f}'s argument in \textit{f's} single argument case 
(in J referred to as the \textit{monadic} case);
the second and third values in \texttt{v} represent the ranks of \texttt{f}'s arguments in \textit{f's} two-argument (\textit{dyadic}) case.
If \texttt{f} has no rank expectations on one of its arguments, 
the corresponding entry for that argument in \texttt{v} is infinity (spelled in J \texttt{\_});
if one of \texttt{f}'s arguments is a scalar, 
the corresponding value is 0 
(in J, scalars are collections of rank 0). %TODO make footnote

For example, most arithmetic functions (such as addition) 
operate on scalar values, and thus have the function rank \texttt{0 0 0}.
These arithmetic functions, and all other functions that operate on scalar values, 
must be extended to operate on collections of rank $n \ge 1$ 
(fortunately, in J these extensions are done automatically).
On the other hand, some functions (like a sort function) take a whole collection as their argument, 
and thus might have the function rank \texttt{\_ \_ \_}.

\subsection{Shape Agreement}
In the cases where a J function \texttt{f} operates on arguments whose ranks match \texttt{f}'s rank, 
\texttt{f} behaves much like a function in programming languages without formalized function rank (c.f. Fig~\ref{fig:j-ig-fr}).
When \texttt{f}'s arguments do not match its function rank, 
J can sometimes automatically extend \texttt{f} to match its arguments.
For example, if \texttt{x} is a scalar and \texttt{c} is a collection of numbers, 
J will automatically extend addition so that \texttt{x} is added to every element of \texttt{c} no matter the rank or shape of \texttt{c} 
(c.f. Fig~\ref{fig:j-def-fr}).

\glsadd{show}
\glsadd{integers}
\glsadd{from}
\glsadd{NB.}

\begin{figure}[htbp]
\begin{quote}
\HRule
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   1 + 1
2
   NB. show. Identity function, used to display results
   show =: ] 

   NB. integers. creates an array with shape given by
   NB. its argument, populated with incrememting values
   NB. starting at 0
   integers =: i. 

   show mat2_3 =: integers 2 3
0 1 2
3 4 5

   NB. from. Indexing into an array, 
   NB. expressed as a function
   from =: { 
   1 from mat2_3
3 4 5
\end{verbatim}
\end{small}
\end{singlespacing}
\HRule
\end{quote}
\caption{Example of J, ignoring function rank}
\label{fig:j-ig-fr}
\end{figure}

\begin{figure}[htbp]
\begin{quote}
\HRule
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   1 + mat2_3
1 2 3
4 5 6
\end{verbatim}
\end{small}
\end{singlespacing}
\HRule
\caption{Example of J with automatic function rank extension}
\label{fig:j-def-fr}
\end{quote}
\end{figure}

In general, J can automatically extend addition (and all other functions on scalars) over two regular collections \texttt{x} and \texttt{y}
if the shape of one collection \textit{prefixes} the other.
Hui called this prefix the frame for the two collections 
and called what remains of the shape vectors of \texttt{x} and \texttt{y} 
after dropping the prefix their respective \texttt{cells}\cite{rankanduni}. 
In this paper we will also say that when a suitable prefix can be found, 
the shapes of \texttt{x} and \texttt{y} agree under the function (e.g., addition).

The examples in Figs~\ref{fig:j-def-fr}, \ref{fig:agree1}, \ref{fig:agree2} illustrate that 
a scalar, a vector of 2 elements, and another 2 by 3 matrix will all agree with \texttt{mat2\_3} under addition, 
since the shapes of the scalar (the empty shape), the vector, and the other matrix would prefix the shape of \texttt{mat2\_3}; 
any collection of rank $n \ge 2$ whose shape begins with $2$ $3$ will also agree with 
\texttt{mat2\_3} under addition, since the shape of \texttt{mat2\_3} prefixes its shape.
In the last example in Figure~\ref{fig:agree3}, 
every scalar of \texttt{mat2\_3} is added to both of the scalars in each vector of \texttt{arr2\_3\_2}. 
Another way to say this is that J made an implicit \textit{map} on the scalar elements of \texttt{mat2\_3}, 
expanding each into a vector of 2 copies of the original scalar.
J can do this because, with a \textit{frame} of \texttt{2 3}, \texttt{mat2\_3}'s \textit{cells} are scalars and 
\texttt{arr2\_3\_2}'s \textit{cells} are vectors of two scalars.

\glsadd{agreement}

\begin{figure}[htbp]\ContinuedFloat*
\begin{quote}
\begin{singlespacing}
\begin{small}
\framebox[\linewidth][l]{
\BVerbatimInput{agree-long-1.txt}
}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing shape agreement. Continued in Fig~\ref{fig:agree2}}
\label{fig:agree1}
\end{figure}

\begin{figure}[htbp]\ContinuedFloat
\begin{quote}
\begin{singlespacing}
\begin{small}
\framebox[\linewidth][l]{
\BVerbatimInput{agree-long-2.txt}
}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing shape agreement. Continued in Fig~\ref{fig:agree3}}
\label{fig:agree2}
\end{figure}

\begin{figure}[hptbp]\ContinuedFloat
\begin{quote}
\begin{singlespacing}
\begin{small}
\subcaptionbox{Addition of \texttt{mat2\_3} and \texttt{arr2\_3\_2}.\label{fig:agree3-1}}[\PartLineWidth]{
	\framebox[\PartLineWidth][c]{
	\BVerbatimInput{agree-long-3.txt}
	}
}% 
\hfill%
\subcaptionbox{Agreement of \texttt{mat2\_3} and \texttt{arr2\_3\_2}.\label{fig:agree3-2}}[\PartLineWidth]{
	\framebox[\PartLineWidth][c]{
	\BVerbatimInput{agree-long-4.txt}
	}
} 
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing shape agreement, part 3.}
\label{fig:agree3}
\end{figure}

\pagebreak

\subsection{Rank Operator}
With what we have developed so far, we are still unable to perform the operation of 
adding a vector \texttt{vec3} of 3 scalars to \texttt{mat2\_3}, since shapes $3$ and $2$ $3$ have no non-empty prefix.

\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   show vec3 =: i. 3
0 1 2
  vec3 + mat2_3
|length error
|   vec3    +mat2_3
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}

\noindent However, it should be possible to add \texttt{vec3} to each of the vectors of \texttt{mat2\_3}, since each vector has the same length.
In order to accomplish this and many similar use cases where the desired extension of a function is not the default extension, 
J also includes a \textit{rank operator} (which is spelled with double quotes: \texttt{"}).
The rank operator is a higher order function which takes as its first argument a function (not higher-ordered) % TODO footnote for taking function?
and as its second argument a vector of 1, 2, or 3 numeric values, 
and returns a function which performs the same operation as the argument function but on the specified data rank\cite{rankanduni}.

Therefore, the following command, 

\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   vec3 +"1 mat2_3
0 2 4
3 5 7
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}

\noindent is read ``add the rank 1 items of \texttt{vec3} to the rank 1 items of \texttt{mat2\_3}.''
In terms of \textit{frames}, \textit{cells}, and implicit \textit{maps}, we say that
the frames of the rank 1 items in \texttt{mat2\_3} and \texttt{vec3} are $2$ and an empty frame, respectively, and they share a common cell size of $3$.
Because the frame at rank 1 of \texttt{vec3} prefixes the same frame \texttt{mat2\_3} (the empty frame prefixes every frame), 
the shapes now agree, and there is an implicit map on the single vector element of \texttt{vec3} expanding to a matrix of two vectors.

\subsection{The Application of a Function with Rank on its Arguments}
\label{fridp}
For any function \texttt{f} with function rank \texttt{r} and arguments \texttt{x} and \texttt{y}, 
the following steps give a high level description of how \texttt{f} is applied to its arguments\cite{rankanduni}.
\begin{enumerate}
	\item Calculate the cell shape at rank \texttt{r} of \texttt{x} and \texttt{y} 
		by taking the \texttt{r} smallest dimensions of the shape vector of each.
		E.g., the cell shape of \texttt{mat2\_3} at rank 1 is 3, since each vector contains 3 items.
	\item Calculate the frame shape at rank \texttt{r} of \texttt{x} and \texttt{y} 
		by removing from the shape vector of each their respective cell shapes.
		E.g, at rank 1, the frame shape of \texttt{mat2\_3} is $2$,
		the frame shape of \texttt{arr2\_3\_2} is $2$ $3$, 
		and the frame shape of \texttt{vec3} is an empty frame.
	\item If the frame shape of \texttt{x} and \texttt{y} do not agree, then return with an error.
		Otherwise, extend the argument with the smaller frame shape via an implicit map on its cells at rank \texttt{r}.
		If the frame shape of \texttt{x} and \texttt{y} are the same, do nothing.
	\item \label{dataparstep}Apply \texttt{f} to every cell at rank \texttt{r} of \texttt{x} and \texttt{y}.
		If \texttt{f} is a user defined function \texttt{u} with function rank \texttt{ru} given with the rank operator,
		(i.e., \texttt{f =: u ("ru)})
		repeat this process with each of the cells of \texttt{x} and \texttt{y}, \texttt{u}, and \texttt{ru}
	\item Reassemble the result cells of the previous step using the agreed frame shape.
\end{enumerate}

\subsection{Inherent Data Parallelism}
While quite a few of these steps have some exploitable concurrency, 
step \ref{dataparstep} has the most potential for performance increases through parallelism.
It is inherently data parallel because each of the cells of $x$ and $y$ are operated on completely independently of each other.
For large computations, it is also the most computationally intensive 
because not only is this step itself recursive, but
also because these cells can themselves be large regular collections.

Finally, one consequence of having this common set of steps for applying all functions with function rank is
that all such functions can be parallelized in the library code.
This means that applications which uses a parallelized function rank library 
can automatically exploit the inherent concurrency of their problem, 
provided this problem can be expressed naturally in terms of function rank.

\section{Other Approaches}
\subsection{Regular Parallel Arrays in Haskel}
\label{repa}
In 2010, Keller et al. published a paper\cite{dph} 
describing work they had done creating a Haskell library, which they named \textit{Repa}, that implements and parallelizes regular arrays.
There is much to commend about their work, including ``that it (1) is purely
functional, (2) supports reuse through shape polymorphism, (3)
avoids unnecessary intermediate structures rather than relying on
subsequent loop fusion, and (4) supports transparent parallelization,''
and that it is a library for a functional language with relatively wide use. 
There are two features of \textit{Repa} specifically 
that influenced work on Parallel-J; 
these are \textit{index functions} and static capture of a collection's shape information.

In order to achieve good performance on functions 
that fall into the family of operations known as \textit{index transformations}, 
such as transposing or shifting a rank 2 array, 
\textit{Repa} formalizes the notion of an \textit{index function}. 
An \textit{index transformation} is an operation on a regular collection that 
conceptually changes how the collection is indexed. 
For example, using a C-style notation, transposition might be represented as 
\texttt{transpose2D(matrix)[i][j] $\Leftrightarrow$ matrix[j][i]}, for all integers $i,j$. 
\textit{Index functions} allow index transformations to be implemented purely as 
a change to how a given collection is indexed, 
rather than by allocating new memory for the transposed collection and copying every element. 
Parallel-J currently lacks this feature, 
but a future Scala regular collections library could easily support index functions.

Impressively, \textit{Repa} also statically captures some of the effects functions have on the shapes of their arguments.
For example, the type signature of \textit{sum} shows that, given a numeric array of rank $n$, 
it returns an array of rank $n-1$ which has the same shape as the argument array 
except for the rightmost (smallest) dimension.
Another way to state this is, their sum library function takes an arbitrary array of rank $n \ge 0$ 
and sums that array's vector elements, 
returning an array whose shape is the shape of the argument array with the smallest dimension dropped off.
Consequently, passing \textit{sum} a rank 0 array is a compile-time error.
In general, this library ``enables [the user] to track the rank of each array in its type,
guaranteeing the absence of rank-related runtime errors''\cite{dph}.

\textit{Repa}'s static capturing of the rank of a function's arguments is equivalent to J's notion of function rank.
It is implemented as a list of the type \textit{Int} and 
uses Haskell's pattern-matching capabilities and some language extensions to analyze the structure of this list.
However, unlike J, Repa appears to lack a rank operator.
Instead, functions must be extended manually in order to operate on arrays of higher rank. 
While \textit{Repa}'s manual extensions are 
safer from error than extending through nested \textit{maps} or \textit{for loops} 
due to its type safety and due to reducing some of the boilerplate code of the latter 
in functions like \textit{replicate} and \textit{backpermute}, 
because it does not express these extensions as higher-ordered functions, 
programmers using \textit{Repa} must still work at a conceptually lower-level of abstraction, 
and still must write more boilerplate code, than using J's rank operator would require of them.

For example, while in J the idiom for \textit{sum} (spelled \texttt{+/}) 
automatically operates on the rank $n-1$ items of a rank $n$ array, 
in Repa, \textit{sum} by default operates only on scalar values in each vector of a collection.
In order to scale the existing \textit{sum} function in Repa to any array of rank $n > 1$, 
a new function must be written for each dimension which manually extends \textit{sum}\cite{dph}.
In contrast, in order to get the same behavior in J of Repa's \textit{sum} function, no manual extension is required; 
it is \texttt{+/ " 1}, which in English reads rather intuitively as ``apply sum to the vector elements of its argument.''

Finally, although both J and Repa support some notion of function rank, 
it seems conceptually easier to understand, for example, 
that \texttt{f (" 3)} means ``apply f on the rank 3 items'', than it is to understand Repa's equivalent, 
\texttt{(sh.:Int.:Int.:Int)} as it would appear in the function declaration below: 

\[\texttt{f :: (Shape sh, Elt e) => Array (sh :. Int :. Int :. Int) e -> Array sh e} \]

\noindent \textit{Repa}'s greater verbosity is partially due to Haskell being statically typed, 
which is what also allows \textit{Repa} to capture the effects operations have on data rank at compile time. 
J, in contrast, is dynamically typed, and while this means J does not provide any mechanisms for catching errors before runtime, 
its functions also do not need to statically document their effects on data, simplifying the way programmers write and use code.

\subsection{SA-C, Boost MultiArray}
While we believe that \textit{Repa} is the best of the solutions we have found so far, 
due to being already parallelized, capturing the effects functions have on the rank of their data, 
and reducing boilerplate code, 
it is appropriate to mention other influential work in the subject of data parallelism on regular collections.
Our analysis is mostly in agreement with the developers of \textit{Repa}\cite{dph}.

Single-Assignment C (\textit{SA-C}) is a functional, C-like language 
that has many of the same advantages as \textit{Repa}\cite{dph}\cite{sac}.
Unfortunately, this also means that it has the same limitations, most notably the lack of a rank operator.
Additionally, unlike \textit{Repa} and our own research (but like J), 
it is a special purpose array programming language and 
not an extension to an existing, general purpose programming with a broad user base and 
with access to large and well developed libraries.

In contrast, the C++ library Boost.MultiArray is a library for a general purpose and widely used programming language\cite{boost}.
However, its ability to analyze and operate on the structure of regular collections is limited compared to SA-C or \textit{Repa}.
Furthermore, it does not benefit from a naturally parallel implementation, 
its arrays are operated on in a conceptually lower (imperative) level, 
and it also does not have an equivalent to the rank operator. 
