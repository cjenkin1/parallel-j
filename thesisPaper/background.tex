\chapter{Background}
\label{back}

\section{Function Rank}
This section provides background information necessary to understand 
the advantages function rank has in exploiting data parallelism over other approaches.

\subsection{History and Definition}
\textit{Function rank} was first developed and described by Kenneth Iverson in a series of research reports written at IBM\cite{rapl}\cite{opandfunc}. 
In one such report, Iverson described it as 
``the most important notion needed to provide a simple and systematic basis for the uniform treatment of all `mixed' or non-scalar functions''\cite{rapl}. % TODO footnote of next comment
Since that time, the idea of function rank has matured and found its way into many dialects of APL, including J.

J's model of function rank is slightly different from what was first presented by Iverson\cite{rankanduni}\cite{jvocab}. 
The rank of a function \texttt{f} in J is a vector \texttt{v} of three values representing the data rank of \texttt{f}'s expected arguments.
Since in J functions take either one or two arguments, 
the first value of \texttt{v} represents the expected data rank of \texttt{f}'s one-argument case (in J referred to as the \textit{monadic} case);
the second and third values in \texttt{v} represent the expected data rank of \texttt{f}'s two-argument (\textit{dyadic}) case.
If \texttt{f} has no restrictions on some or all of its arguments, 
this is represented in \texttt{v} with the value for infinity, spelled \texttt{\_} ;
if \texttt{f} operates on scalar values, this is represented as an entry in \texttt{v} of 0 
(in J, scalars are collections of rank 0 and an empty shape vector). % TODO make footnote

Thus, for example, most arithmetic functions, such as addition, 
fundamentally operate on scalar values, and thus usually have the function rank \texttt{0 0 0}.
These arithmetic functions, and all others which operate on scalar values, 
must be extended, whether manually by the programmer or automatically by the J environment, 
to operate on collections of rank $n \ge 1$.
On the other hand, most collective operations, such as using an integer to index into collection (which has rank \texttt{0 \_}), 
sorting a collection, and getting the shape of an array (both of which have rank \texttt{\_}), operate on whole collections at once.
In the above example, function ranks with only 2 elements represent the J primitive's dyadic use cases; 
similarly for the function ranks with only 1 element and J's monads. % TODO footnote?

\subsection{Shape Agreement}
In the trivial cases, where a function \texttt{f} is given arguments with ranks matching \texttt{f}'s function rank, 
J behaves much like any programming language without formalized function rank (c.f. Fig~\ref{fig:j-ig-fr}). 
In some cases, when the arguments to \texttt{f} do not match its function rank, 
\texttt{f} is automatically extended to the appropriate dimensions.
For example, if \texttt{x} is a scalar, addition can always be extended 
so that \texttt{x} is added to every element of a collection \texttt{c} no matter \texttt{c}'s rank or shape. 
This automatic extension is demonstrated in Fig~\ref{fig:j-def-fr}

\glsadd{show}
\glsadd{integers}
\glsadd{from}
\glsadd{NB.}

\begin{figure}[htbp]
\begin{quote}
\HRule
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   1 + 1
2
   show =: ] NB. Identity, used to display results
   integers =: i. NB. creates array with shape of argument
   NB.                populated with an incrementing value
   NB.                starting at 0
   show mat2_3 =: integers 2 3
0 1 2
3 4 5
   from =: { NB. Indexing into an array
   NB.           expressed as a function
   1 from mat2_3
3 4 5
\end{verbatim}
\end{small}
\end{singlespacing}
\HRule
\end{quote}
\caption{Example of J, ignoring function rank}
\label{fig:j-ig-fr}
\end{figure}

\begin{figure}[htbp]
\begin{quote}
\HRule
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   1 + mat2_3
1 2 3
4 5 6
\end{verbatim}
\end{small}
\end{singlespacing}
\HRule
\caption{Example of J with automatic function rank extension}
\label{fig:j-def-fr}
\end{quote}
\end{figure}

In general, addition (and all other scalar functions) can be extended automatically over two regular collections \texttt{x} and \texttt{y}  
if the shape of one collection \textit{prefixes} the other.
This is called \textit{prefix shape agreement}, or just \textit{shape agreement}, 
and in this paper we will say when this happens that ``the shapes of \texttt{x} and \texttt{y} agree under addition''\cite{rankanduni}.
We also say that this prefix is the \textit{frame} for the two collections,
and what remains of the shape vectors of \texttt{x} and \texttt{y} after dropping the prefix are their respective \textit{cells}.

Going back to the above example: 
a scalar, a vector of 2 elements, and another 2 by 3 matrix will agree with \texttt{mat2\_3} under addition, 
since the shapes of the scalar (empty shape), the vector, and the other matrix would prefix the shape of \texttt{mat2\_3}; 
any collection of rank $n \ge 2$ whose shape begins with $2$ $3$ will also agree with 
\texttt{mat2\_3} under addition, since the shape of \texttt{mat2\_3} would prefix its shape.
In this last example in Figure~\ref{fig:agree3}, 
every scalar of \texttt{mat2\_3} was added to both scalars of each vector in \texttt{arr2\_3\_2}. 
Another way to conceptualize this is that J made an implicit \textit{map} on the scalar elements of \texttt{mat2\_3}, 
expanding each into a vector of 2 scalars.
J could do this because, with a \textit{frame} of \texttt{2 3}, \texttt{mat2\_3}'s \textit{cells} were scalars and 
\texttt{arr2\_3\_2}'s \textit{cells} were vectors of two scalars.

\glsadd{agreement}

\begin{figure}[htbp]\ContinuedFloat*
\begin{quote}
\begin{singlespacing}
\begin{small}
\framebox[\linewidth][l]{
\BVerbatimInput{agree-long-1.txt}
}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing shape agreement. Continued in Fig~\ref{fig:agree2}}
\label{fig:agree1}
\end{figure}

\begin{figure}[htbp]\ContinuedFloat
\begin{quote}
\begin{singlespacing}
\begin{small}
\framebox[\linewidth][l]{
\BVerbatimInput{agree-long-2.txt}
}
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing shape agreement. Continued in Fig~\ref{fig:agree3}}
\label{fig:agree2}
\end{figure}

\begin{figure}[hptbp]\ContinuedFloat
\begin{quote}
\begin{singlespacing}
\begin{small}
\subcaptionbox{Addition of \texttt{mat2\_3} and \texttt{arr2\_3\_2}.\label{fig:agree3-1}}[\PartLineWidth]{
	\framebox[\PartLineWidth][c]{
	\BVerbatimInput{agree-long-3.txt}
	}
}% 
\hfill%
\subcaptionbox{Agreement of \texttt{mat2\_3} and \texttt{arr2\_3\_2}.\label{fig:agree3-2}}[\PartLineWidth]{
	\framebox[\PartLineWidth][c]{
	\BVerbatimInput{agree-long-4.txt}
	}
} 
\end{small}
\end{singlespacing}
\end{quote}
\caption{Visualizing shape agreement, part 3.}
\label{fig:agree3}
\end{figure}

\pagebreak

\subsection{Rank Operator}
With what we have developed so far, we are still unable to perform the operation of 
adding a vector \texttt{vec3} of 3 scalars to \texttt{mat2\_3}, since shapes $3$ and $2$ $3$ have no non-empty prefix.

\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   show vec3 =: i. 3
0 1 2
  vec3 + mat2_3
|length error
|   vec3    +mat2_3
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}

\noindent However, it should be possible to add \texttt{vec3} to each of the vectors of \texttt{mat2\_3}, since each vector has the same length.
In order to accomplish this and many similar use cases where the desired extension of a function is not the default extension, 
J also includes a \textit{rank operator} (which is spelled with double quotes: \texttt{"}).
The rank operator is a higher order function which takes as its first argument a function (not higher-ordered) % TODO footnote for taking function?
and as its second argument a vector of 1, 2, or 3 numeric values, 
and returns a function which performs the same operation as the argument function but on the specified data rank\cite{rankanduni}.

Therefore, the following command, 

\begin{quote}
\begin{singlespacing}
\begin{small}
\begin{verbatim}
   vec3 +"1 mat2_3
0 2 4
3 5 7
\end{verbatim}
\end{small}
\end{singlespacing}
\end{quote}

\noindent is read ``add the rank 1 items of \texttt{vec3} to the rank 1 items of \texttt{mat2\_3}.''
In terms of \textit{frames}, \textit{cells}, and implicit \textit{maps}, we say that
the frames of the rank 1 items in \texttt{mat2\_3} and \texttt{vec3} are $2$ and an empty frame, respectively, and they share a common cell size of $3$.
Because the frame at rank 1 of \texttt{vec3} prefixes the same frame \texttt{mat2\_3} (the empty frame prefixes every frame), 
the shapes now agree, and there is an implicit map on the single vector element of \texttt{vec3} expanding to a matrix of two vectors.

\subsection{The Application of a Function with Rank on its Arguments}
\label{fridp}
For any function \texttt{f} with function rank \texttt{r} and arguments \texttt{x} and \texttt{y}, 
the following steps give a high level description of how \texttt{f} is applied to its arguments\cite{rankanduni}.
\begin{enumerate}
	\item Calculate the cell shape at rank \texttt{r} of \texttt{x} and \texttt{y} 
		by taking the \texttt{r} smallest dimensions of the shape vector of each.
		E.g., the cell shape of \texttt{mat2\_3} at rank 1 is 3, since each vector contains 3 items.
	\item Calculate the frame shape at rank \texttt{r} of \texttt{x} and \texttt{y} 
		by removing from the shape vector of each their respective cell shapes.
		E.g, at rank 1, the frame shape of \texttt{mat2\_3} is $2$,
		the frame shape of \texttt{arr2\_3\_2} is $2$ $3$, 
		and the frame shape of \texttt{vec3} is an empty frame.
	\item If the frame shape of \texttt{x} and \texttt{y} do not agree, then return with an error.
		Otherwise, extend the argument with the smaller frame shape via an implicit map on its cells at rank \texttt{r}.
		If the frame shape of \texttt{x} and \texttt{y} are the same, do nothing.
	\item \label{dataparstep}Apply \texttt{f} to every cell at rank \texttt{r} of \texttt{x} and \texttt{y}.
		If \texttt{f} is a user defined function \texttt{u} with function rank \texttt{ru} given with the rank operator,
		(i.e., \texttt{f =: u ("ru)})
		repeat this process with each of the cells of \texttt{x} and \texttt{y}, \texttt{u}, and \texttt{ru}
	\item Reassemble the result cells of the previous step using the agreed frame shape.
\end{enumerate}

\subsection{Inherent Data Parallelism}
While quite a few of these steps have some exploitable concurrency, 
step \ref{dataparstep} has the most potential for performance increases through parallelism.
It is inherently data parallel because each of the cells of $x$ and $y$ are operated on completely independently of each other.
For large computations, it is also the most computationally intensive 
because not only is this step itself recursive, but
also because these cells can themselves be large regular collections.

Finally, one consequence of having this common set of steps for applying all functions with function rank is
that all such functions can be parallelized in the library code.
This means that applications which uses a parallelized function rank library 
can automatically exploit the inherent concurrency of their problem, 
provided this problem can be expressed naturally in terms of function rank.

\section{Other Approaches}
\subsection{Regular Parallel Arrays in Haskel}
\label{repa}
In 2010, Keller et al. published a paper\cite{dph} 
describing work they had done creating a Haskell library, which they named \textit{Repa}, that implements and parallelizes regular arrays.
There is much to commend about their work, including ``that it (1) is purely
functional, (2) supports reuse through shape polymorphism, (3)
avoids unnecessary intermediate structures rather than relying on
subsequent loop fusion, and (4) supports transparent parallelization,''
and that it is a library for a functional language with relatively wide use. 
There are two features of \textit{Repa} specifically 
that influenced work on Parallel-J; 
these are \textit{index functions} and static capture of a collection's shape information.

In order to achieve good performance on functions 
that fall into the family of operations known as \textit{index transformations}, 
such as transposing or shifting a rank 2 array, 
\textit{Repa} formalizes the notion of an \textit{index function}. 
An \textit{index transformation} is an operation on a regular collection that 
conceptually changes how the collection is indexed. 
For example, using a C-style notation, transposition might be represented as 
\texttt{transpose2D(matrix)[i][j] $\Leftrightarrow$ matrix[j][i]}, for all integers $i,j$. 
\textit{Index functions} allow index transformations to be implemented purely as 
a change to how a given collection is indexed, 
rather than by allocating new memory for the transposed collection and copying every element. 
Parallel-J currently lacks this feature, 
but a future Scala regular collections library could easily support index functions.

Impressively, \textit{Repa} also statically captures some of the effects functions have on the shapes of their arguments.
For example, the type signature of \textit{sum} shows that, given a numeric array of rank $n$, 
it returns an array of rank $n-1$ which has the same shape as the argument array 
except for the rightmost (smallest) dimension.
Another way to state this is, their sum library function takes an arbitrary array of rank $n \ge 0$ 
and sums that array's vector elements, 
returning an array whose shape is the shape of the argument array with the smallest dimension dropped off.
Consequently, passing \textit{sum} a rank 0 array is a compile-time error.
In general, this library ``enables [the user] to track the rank of each array in its type,
guaranteeing the absence of rank-related runtime errors''\cite{dph}.

\textit{Repa}'s static capturing of the rank of a function's arguments is equivalent to J's notion of function rank.
It is implemented as a list of the type \textit{Int} and 
uses Haskell's pattern-matching capabilities and some language extensions to analyze the structure of this list.
However, unlike J, Repa appears to lack a rank operator.
Instead, functions must be extended manually in order to operate on arrays of higher rank. 
While \textit{Repa}'s manual extensions are 
safer from error than extending through nested \textit{maps} or \textit{for loops} 
due to its type safety and due to reducing some of the boilerplate code of the latter 
in functions like \textit{replicate} and \textit{backpermute}, 
because it does not express these extensions as higher-ordered functions, 
programmers using \textit{Repa} must still work at a conceptually lower-level of abstraction, 
and still must write more boilerplate code, than using J's rank operator would require of them.

For example, while in J the idiom for \textit{sum} (spelled \texttt{+/}) 
automatically operates on the rank $n-1$ items of a rank $n$ array, 
in Repa, \textit{sum} by default operates only on scalar values in each vector of a collection.
In order to scale the existing \textit{sum} function in Repa to any array of rank $n > 1$, 
a new function must be written for each dimension which manually extends \textit{sum}\cite{dph}.
In contrast, in order to get the same behavior in J of Repa's \textit{sum} function, no manual extension is required; 
it is \texttt{+/ " 1}, which in English reads rather intuitively as ``apply sum to the vector elements of its argument.''

Finally, although both J and Repa support some notion of function rank, 
it seems conceptually easier to understand, for example, 
that \texttt{f (" 3)} means ``apply f on the rank 3 items'', than it is to understand Repa's equivalent, 
\texttt{(sh.:Int.:Int.:Int)} as it would appear in the function declaration below: 

\[\texttt{f :: (Shape sh, Elt e) => Array (sh :. Int :. Int :. Int) e -> Array sh e} \]

\noindent \textit{Repa}'s greater verbosity is partially due to Haskell being statically typed, 
which is what also allows \textit{Repa} to capture the effects operations have on data rank at compile time. 
J, in contrast, is dynamically typed, and while this means J does not provide any mechanisms for catching errors before runtime, 
its functions also do not need to statically document their effects on data, simplifying the way programmers write and use code.

\subsection{SA-C, Boost MultiArray}
While we believe that \textit{Repa} is the best of the solutions we have found so far, 
due to being already parallelized, capturing the effects functions have on the rank of their data, 
and reducing boilerplate code, 
it is appropriate to mention other influential work in the subject of data parallelism on regular collections.
Our analysis is mostly in agreement with the developers of \textit{Repa}\cite{dph}.

Single-Assignment C (\textit{SA-C}) is a functional, C-like language 
that has many of the same advantages as \textit{Repa}\cite{dph}\cite{sac}.
Unfortunately, this also means that it has the same limitations, most notably the lack of a rank operator.
Additionally, unlike \textit{Repa} and our own research (but like J), 
it is a special purpose array programming language and 
not an extension to an existing, general purpose programming with a broad user base and 
with access to large and well developed libraries.

In contrast, the C++ library Boost.MultiArray is a library for a general purpose and widely used programming language\cite{boost}.
However, its ability to analyze and operate on the structure of regular collections is limited compared to SA-C or \textit{Repa}.
Furthermore, it does not benefit from a naturally parallel implementation, 
its arrays are operated on in a conceptually lower (imperative) level, 
and it also does not have an equivalent to the rank operator. 
